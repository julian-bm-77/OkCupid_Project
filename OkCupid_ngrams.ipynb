{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "developing-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import wordcloud as wc\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def csv_to_df(filename):\n",
    "    ''' Function: csv_to_df\n",
    "        Parameters: filename (string), header (list)\n",
    "        Returns: dataframe containing information from\n",
    "                the file and headers from input\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(filename) #,names = header)\n",
    "    return df\n",
    "\n",
    "def okcupid_regex(df):\n",
    "    ''' Function: okcupid_regex\n",
    "        Parameters: df (dataframe)\n",
    "        Returns: dataframe sanitized of HTML tags\n",
    "    '''\n",
    "    for col in df:\n",
    "        if df.dtypes[col] == np.object or df.dtypes[col] == str:\n",
    "            df[col] = df[col].str.replace(r'<[^>]+>','',regex=True)\n",
    "            df[col] = df[col].str.replace('\\n',' ',regex=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_txt(text):\n",
    "    ''' Function: read_txt\n",
    "        Parameters: name of speech file (string)\n",
    "        Returns: the text (string) but with punctuation, \n",
    "            square brackets, and weird line breaks removed\n",
    "    '''\n",
    "\n",
    "    text = re.sub(r'<[^>]+>','',text)\n",
    "    text = re.sub('\\[.+\\]','',text)\n",
    "    text = re.sub('\\<.+\\>','',text)\n",
    "    text = re.sub('[^\\w\\s]','',text)\n",
    "    text = re.sub('href','',text) #my attempt at removing added linebreaks (temporary)\n",
    "    text = re.sub('br','',text) #my attempt at removing added linebreaks (temporary)\n",
    "    text = re.sub('\\n',' ',text) #my attempt at removing added linebreaks (temporary)\n",
    "    return text\n",
    "\n",
    "\n",
    "def combine_essay0(df):\n",
    "    ''' Function: combine_essay0\n",
    "        Parameters: df (dataframe)\n",
    "        Returns: list of each user's essay0, cleaned\n",
    "    '''\n",
    "    essay = []\n",
    "    for i in range(len(df)):\n",
    "        text = df.loc[i,'essay0']\n",
    "        x = read_txt(text)\n",
    "        essay.append(x)\n",
    "\n",
    "\n",
    "    return essay\n",
    "\n",
    "\n",
    "\n",
    "def generate_lyric(begin, ending, ngrams):\n",
    "    ''' Function: generate_lyric\n",
    "        Parameters: list of begin-words, list of end-words,\n",
    "                    dictionary of key = word, value = list of followed-by\n",
    "        Returns: one line of a lyric\n",
    "    '''\n",
    "    sentence = \"\"\n",
    "    curr_word = random.choice(begin)\n",
    "    while True:\n",
    "        sentence += \" \" + curr_word\n",
    "        if curr_word in ending:\n",
    "            break\n",
    "        curr_word = random.choice(ngrams[curr_word])\n",
    "    return sentence\n",
    "\n",
    "def get_ngram(text):\n",
    "    ''' Function: get_ngram\n",
    "        Parameters: text (list of strings)\n",
    "        Returns: one line of a lyric\n",
    "    '''\n",
    "\n",
    "    first_word_list = []\n",
    "    last_word_list = []\n",
    "    lyrics_dic = {}\n",
    "    for i in range(100): #if it's too big then too many stopping words\n",
    "        if text[i] == ' ':\n",
    "            continue\n",
    "        text[i] = text[i].split()\n",
    "        first_word_list.append(text[i][0]) #creating list of first words\n",
    "        last_word_list.append(text[i][-1]) #creating list of last words\n",
    "        \n",
    "        #creating a dictionary where key: word, value: list of words that comes after key in a sentence\n",
    "        for j in range(len(text[i])):\n",
    "            if j <= len(text[i]) - 2:\n",
    "                if text[i][j] in lyrics_dic:\n",
    "                    lyrics_dic[text[i][j]].append(text[i][j+1])\n",
    "                else:\n",
    "                    match_list = []\n",
    "                    match_list.append(text[i][j+1])\n",
    "                    lyrics_dic[text[i][j]] = match_list\n",
    "    return first_word_list, last_word_list, lyrics_dic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "everyday-swedish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i write runon sentences for school. i do. im being a regular basis coping with me. learning new. living it.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    okcupid = 'profiles.csv.zip'\n",
    "    df = csv_to_df(okcupid)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    essay = combine_essay0(df)\n",
    "    first_word_list, last_word_list, lyrics_dic = get_ngram(essay)\n",
    "    \n",
    "    sentence = ''\n",
    "    for i in range(5):\n",
    "        sentence += generate_lyric(first_word_list,last_word_list,lyrics_dic)\n",
    "        sentence += '.'\n",
    "    print(sentence)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
